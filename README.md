# min-llm-front

A minimal LLM chat frontend. 

It is useful for experimenting with OpenAI or OpenAI compatible chat completions API's.

See [min-llm-back](https://github.com/wensheng/min-llm-back) for how to quickly set up an OpenAI compatible API server.

### Development

`npm install`

`npm start`: Runs the app in the development mode. Open http://localhost:3000 to view it in the browser.

`npm run build`: Builds the app for production to the `build` folder.
